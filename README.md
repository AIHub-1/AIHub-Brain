# AI Hub
![header](https://capsule-render.vercel.app/api?type=waving&color=auto&height=300&section=header&text=AI%20Hub&fontColor=3C3C1F&fontSize=90&animation=fadeIn&fontAlignY=38&desc=%20AI%20Innovation%20Hub%20BCI%20Project&descAlignY=51&descAlign=62)

<div align=left>
	<b>-AI Hub Project Introduction-</b>
</div>


<div align=left>
	<h1>ğŸ§  Starlab ğŸ§ </h1>
		<b>The open software package, designed for developing Brain-Computer Interfaces (BCIs) with various advanced pattern recognition algorithms.</b>
		<ul>
			<li>Example codes for Motor Imagination (MI), Event-Related Potential (ERP), and Steady-State Visually Evoked 				Potential (SSVEP) in the 'Examples' folder.</li>
			<li>The package also features 'BMI_modules' with implementation functions, 'GUI module' for Graphic User Interface functions, and 'Paradigm' 					functions using Psychtoolbox.</li>
			<li>Additionally, it contains codes from other BCI groups and an OpenBMI demo. For questions or more information, visit http://openbmi.org.</li>
		</ul>
</div>

<div align=left>
<h1>ğŸ—£ï¸ NeuroTalk ğŸ—£ï¸</h1>
	<b>Voice Reconstruction from Brain Signals</b>
		<p>The algorithm aimed at reconstructing voice from EEG during imagined speech.</p>
	<b>Key Contributions</b>
		<ul>
			<li>A generative model capable of extracting frequency characteristics and sequential information from neural signals to generate 				speech.</li>
			<li>Addressed the constraint of imagined speech-based BTS system lacking ground truth voice by employing a domain adaptation method.</li>
			<li>Demonstrated the potential of robust speech generation by training only several words or phrases, with the model showing capability to learn 				phoneme level information from brain signals.</li>
			<li>This work is currently under review for presentation at AAAI 2023.</li>
		</ul>
</div>

<div align=left>
	<h1>ğŸ” GigaScience ğŸ”</h1>
		<b>Comprehensive collection of EEG signal preprocess/analysis codes</b>
			<ul>
				<li>It primarily focuses on the analysis of EEG data.</li>
				<li>This folder features different versions for Motor Imagery (MI), Steady-State Visual Evoked Potential (SSVEP), and Event-Related Potential (ERP).</li>
				<li>It serves as an invaluable resource for neuroscience researchers and data scientists.</li>
				<li>This content is particularly useful for those interested in EEG data processing and brain-computer interfaces.</li>
			</ul>
</div>

<div align=left>
	<h1>ğŸï¸ Diff-E ğŸï¸</h1>
		<b>EEG Imagined Speech Decoding Using Diffusion-based Learning </b>
			<p>Decoding EEG signals for imagined speech has been a complex task, primarily due to the high-dimensional nature of the data and a low signal-to-noise ratio.</p>
		<b>Key Contributions</b>
			<ul>
				<li>Our study introduces Diff-E, a novel method that utilizes denoising diffusion probabilistic models (DDPMs) and a conditional 						autoencoder to address these challenges.</li>
				<li>We've found that Diff-E substantially outperforms traditional machine learning techniques and baseline models in terms of decoding 					accuracy.</li> 
				<li>These findings indicate the potential effectiveness of DDPMs for EEG signal decoding, suggesting possible applications in the 						development of brain-computer interfaces that enable communication through imagined speech.</li>
				<li>This work is currently under review for presentation at Interspeech 2023.</li>
			</ul>
</div>

<div align=left>
	<h1>ğŸŠâ€â™€ï¸ TNNLS ğŸŠâ€â™€ï¸</h1>
		<b>Motor imagination brain signal analysis codes</b>
			<ul>
				<li>This folder provides comprehensive analysis codes for motor imagination, including pre-processing, feature extraction, 							classification, and evaluation modules.</li>
				<li>It includes codes for a basic motor imagination paradigm and example codes for setting up experiments and conducting analysis.</li>
				<li>For inquiries, refer to the website http://openbmi.org.</li>
			<ul>
</div>
				
<!--
<div align=left>
	<h1>ğŸ§  Sementics ğŸ§ </h1>
		<b>aaa</b>
			<p>aaa</p>
</div>

<div align=left>
	<h1>ğŸ§  OnlineDemo ğŸ§ </h1>
		<b>aaa</b>
			<p>aaa<p>
</div>
-->
<hr>
<div align=center>
	<h3>ğŸ˜Collaborator!ğŸ˜</h3>
		<p>
			<a href="ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œ ì´ë™í•  ë§í¬" target="_blank"><img src="https://img.shields.io/badge/S.-H. Lee-41454A?style=plastic&logo=aerlingus&logoColor=FF6347"/></a>
			<a href="https://github.com/yorgoon" target="_blank"><img src="https://img.shields.io/badge/S. Kim-41454A?style=plastic&logo=aerlingus&logoColor=4169E1"/></a>
			<a href="https://github.com/youngeun1209" target="_blank"><img src="https://img.shields.io/badge/Y.-E. Lee-41454A?style=plastic&logo=aerlingus&logoColor=3CB371"/></a>
			<a href="ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œ ì´ë™í•  ë§í¬" target="_blank"><img src="https://img.shields.io/badge/B.K. Ko-41454A?style=plastic&logo=aerlingus&logoColor=FFD700"/></a>
		</p>
		<p>
			<a href="https://github.com/jiwonLee-KU" target="_blank"><img src="https://img.shields.io/badge/J.-W. Lee-41454A?style=plastic&logo=aerlingus&logoColor=9370DB"/></a>
			<a href="ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œ ì´ë™í•  ë§í¬" target="_blank"><img src="https://img.shields.io/badge/J.-S. Lee-41454A?style=plastic&logo=aerlingus&logoColor=FF7F50"/></a>
			<a href="https://github.com/rlawnsdud99" target="_blank"><img src="https://img.shields.io/badge/J.-Y. Kim-41454A?style=plastic&logo=aerlingus&logoColor=87CEFA"/></a>
			<a href="https://github.com/park-jiha" target="_blank"><img src="https://img.shields.io/badge/J.-H. Park-41454A?style=plastic&logo=aerlingus&logoColor=32CD32"/></a>
			<a href="https://github.com/deokseonKim" target="_blank"><img src="https://img.shields.io/badge/D.-S. Kim-41454A?style=plastic&logo=aerlingus&logoColor=F08080"/></a>
		</p>
</div>

<div align=center>
	<h3>ğŸš€Contact!ğŸš€</h3>
		<p>
			<a href="mailto:j_y_kim@korea.ac.kr" target="_blank"><img src="https://img.shields.io/badge/j_y_kim@korea.ac.kr-41454A?style=plastic&logo=naver&logoColor=#03C75A"/></a>
		</p>
</div>

